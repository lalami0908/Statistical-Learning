{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ETkVqrirBVe"
   },
   "source": [
    "# b06705048_hw3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OKzOibG4rKR5"
   },
   "source": [
    "## Load package and data\n",
    "Load packages and data, and then standardize all feature values.\n",
    "Now, we have data："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ckNByJa6hqZ"
   },
   "source": [
    "## Q1.1\n",
    "1. Clean up the dataset \n",
    "2. create x_train, y_train, x_test, y_test for training feature, training value, test feature, test label. \n",
    "3. All of these variables should be numpy arrays. \n",
    "4. Provide summary statistics for your training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4lc5DvFxrNFh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1153,
     "status": "ok",
     "timestamp": 1587627256180,
     "user": {
      "displayName": "lalami",
      "photoUrl": "",
      "userId": "13790229632949164922"
     },
     "user_tz": -480
    },
    "id": "HsV4fYZUzly2",
    "outputId": "a3512b21-f25a-4835-8588-0f013aae235b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 15)\n",
      "(16281, 15)\n"
     ]
    }
   ],
   "source": [
    "train=pd.read_csv(\"train.csv\",header=None)\n",
    "test=pd.read_csv(\"test.csv\",header=None)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kji2BdzK5G3m"
   },
   "outputs": [],
   "source": [
    "all = [\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"income\"]\n",
    "train.columns = all\n",
    "test.columns = train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  income  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age   workclass  fnlwgt      education  education-num       marital-status  \\\n",
       "0   25     Private  226802           11th              7        Never-married   \n",
       "1   38     Private   89814        HS-grad              9   Married-civ-spouse   \n",
       "2   28   Local-gov  336951     Assoc-acdm             12   Married-civ-spouse   \n",
       "3   44     Private  160323   Some-college             10   Married-civ-spouse   \n",
       "4   18           ?  103497   Some-college             10        Never-married   \n",
       "\n",
       "           occupation relationship    race      sex  capital-gain  \\\n",
       "0   Machine-op-inspct    Own-child   Black     Male             0   \n",
       "1     Farming-fishing      Husband   White     Male             0   \n",
       "2     Protective-serv      Husband   White     Male             0   \n",
       "3   Machine-op-inspct      Husband   Black     Male          7688   \n",
       "4                   ?    Own-child   White   Female             0   \n",
       "\n",
       "   capital-loss  hours-per-week  native-country   income  \n",
       "0             0              40   United-States   <=50K.  \n",
       "1             0              50   United-States   <=50K.  \n",
       "2             0              40   United-States    >50K.  \n",
       "3             0              40   United-States    >50K.  \n",
       "4             0              30   United-States   <=50K.  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TY_hhFIn5YH8"
   },
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "##  You should remove all rows with missing values. \n",
    "for i in train.columns:\n",
    "    train[i] = train[i].replace(' ?', value = np.nan)\n",
    "    test[i] = test[i].replace(' ?', value = np.nan)\n",
    "test.dropna(inplace = True)\n",
    "train.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30162, 15)\n",
      "(15060, 15)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1127,
     "status": "ok",
     "timestamp": 1587627275066,
     "user": {
      "displayName": "lalami",
      "photoUrl": "",
      "userId": "13790229632949164922"
     },
     "user_tz": -480
    },
    "id": "MmUy7GGd5qM4",
    "outputId": "a32d8327-21fd-43a7-ba49-c01c230af4b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: workclass, dtype: int64)\n",
      "Series([], Name: education, dtype: int64)\n",
      "Series([], Name: marital-status, dtype: int64)\n",
      " Armed-Forces    9\n",
      "Name: occupation, dtype: int64\n",
      "Series([], Name: relationship, dtype: int64)\n",
      "Series([], Name: race, dtype: int64)\n",
      "Series([], Name: sex, dtype: int64)\n",
      " Holand-Netherlands    1\n",
      "Name: native-country, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "##  Include a particular feature value only if this unique value appears more than ten times in the training data.\n",
    "text = [\"workclass\",\"education\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"native-country\"]\n",
    "for i in text:\n",
    "    print(train[i].value_counts()[train[i].value_counts() < 10])\n",
    "# find：Armed-Forces /  Holand-Netherlands  will be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All features with discrete-values \n",
    "## for example, native-country and workclass should be converted to \"1-of-K\" encoding.\n",
    "train = pd.concat([train.drop(text,axis=1),pd.get_dummies(train[text])],axis=1)\n",
    "test = pd.concat([test.drop(text,axis=1),pd.get_dummies(test[text])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30162, 105)\n",
      "(15060, 104)\n",
      "native-country_ Holand-Netherlands not in test\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "for i in range(len(train.columns)):\n",
    "    if train.columns[i] not in test.columns:\n",
    "        print(train.columns[i],\"not in test\")\n",
    "        #test.insert(i,train.columns[i],0)\n",
    "for i in range(len(test.columns)):\n",
    "    if test.columns[i] not in train.columns:\n",
    "        print(test.columns[i],\"not in train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop([\"occupation_ Armed-Forces\",\"native-country_ Holand-Netherlands\"],axis=1,inplace=True)\n",
    "test.drop([\"occupation_ Armed-Forces\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30162, 103)\n",
      "(15060, 103)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "60pVzR966Tsj"
   },
   "outputs": [],
   "source": [
    "mapping={\" >50K\":1,\" <=50K\":0}\n",
    "y_train=pd.DataFrame([])\n",
    "y_train=train[\"income\"].map(mapping)\n",
    "mapping2={\" >50K.\":1,\" <=50K.\":0}\n",
    "y_test=pd.DataFrame([])\n",
    "y_test=test[\"income\"].map(mapping2)\n",
    "x_train=train.drop(\"income\",axis=1)\n",
    "x_test=test.drop(\"income\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30162, 102)\n",
      "(30162,)\n",
      "(15060, 102)\n",
      "(15060,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>workclass_ Private</th>\n",
       "      <th>workclass_ Self-emp-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_ Portugal</th>\n",
       "      <th>native-country_ Puerto-Rico</th>\n",
       "      <th>native-country_ Scotland</th>\n",
       "      <th>native-country_ South</th>\n",
       "      <th>native-country_ Taiwan</th>\n",
       "      <th>native-country_ Thailand</th>\n",
       "      <th>native-country_ Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_ United-States</th>\n",
       "      <th>native-country_ Vietnam</th>\n",
       "      <th>native-country_ Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30162.000000</td>\n",
       "      <td>3.016200e+04</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.437902</td>\n",
       "      <td>1.897938e+05</td>\n",
       "      <td>10.121312</td>\n",
       "      <td>1092.007858</td>\n",
       "      <td>88.372489</td>\n",
       "      <td>40.931238</td>\n",
       "      <td>0.031265</td>\n",
       "      <td>0.068530</td>\n",
       "      <td>0.738877</td>\n",
       "      <td>0.035608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.003614</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.002354</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.911876</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>0.000530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.134665</td>\n",
       "      <td>1.056530e+05</td>\n",
       "      <td>2.549995</td>\n",
       "      <td>7406.346497</td>\n",
       "      <td>404.298370</td>\n",
       "      <td>11.979984</td>\n",
       "      <td>0.174035</td>\n",
       "      <td>0.252657</td>\n",
       "      <td>0.439254</td>\n",
       "      <td>0.185313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033556</td>\n",
       "      <td>0.060007</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.048461</td>\n",
       "      <td>0.037291</td>\n",
       "      <td>0.023734</td>\n",
       "      <td>0.024422</td>\n",
       "      <td>0.283480</td>\n",
       "      <td>0.046016</td>\n",
       "      <td>0.023026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.376900e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.176272e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.784250e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>2.376285e+05</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.484705e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "count  30162.000000  3.016200e+04   30162.000000  30162.000000  30162.000000   \n",
       "mean      38.437902  1.897938e+05      10.121312   1092.007858     88.372489   \n",
       "std       13.134665  1.056530e+05       2.549995   7406.346497    404.298370   \n",
       "min       17.000000  1.376900e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.176272e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.784250e+05      10.000000      0.000000      0.000000   \n",
       "75%       47.000000  2.376285e+05      13.000000      0.000000      0.000000   \n",
       "max       90.000000  1.484705e+06      16.000000  99999.000000   4356.000000   \n",
       "\n",
       "       hours-per-week  workclass_ Federal-gov  workclass_ Local-gov  \\\n",
       "count    30162.000000            30162.000000          30162.000000   \n",
       "mean        40.931238                0.031265              0.068530   \n",
       "std         11.979984                0.174035              0.252657   \n",
       "min          1.000000                0.000000              0.000000   \n",
       "25%         40.000000                0.000000              0.000000   \n",
       "50%         40.000000                0.000000              0.000000   \n",
       "75%         45.000000                0.000000              0.000000   \n",
       "max         99.000000                1.000000              1.000000   \n",
       "\n",
       "       workclass_ Private  workclass_ Self-emp-inc  ...  \\\n",
       "count        30162.000000             30162.000000  ...   \n",
       "mean             0.738877                 0.035608  ...   \n",
       "std              0.439254                 0.185313  ...   \n",
       "min              0.000000                 0.000000  ...   \n",
       "25%              0.000000                 0.000000  ...   \n",
       "50%              1.000000                 0.000000  ...   \n",
       "75%              1.000000                 0.000000  ...   \n",
       "max              1.000000                 1.000000  ...   \n",
       "\n",
       "       native-country_ Portugal  native-country_ Puerto-Rico  \\\n",
       "count              30162.000000                 30162.000000   \n",
       "mean                   0.001127                     0.003614   \n",
       "std                    0.033556                     0.060007   \n",
       "min                    0.000000                     0.000000   \n",
       "25%                    0.000000                     0.000000   \n",
       "50%                    0.000000                     0.000000   \n",
       "75%                    0.000000                     0.000000   \n",
       "max                    1.000000                     1.000000   \n",
       "\n",
       "       native-country_ Scotland  native-country_ South  \\\n",
       "count              30162.000000           30162.000000   \n",
       "mean                   0.000365               0.002354   \n",
       "std                    0.019094               0.048461   \n",
       "min                    0.000000               0.000000   \n",
       "25%                    0.000000               0.000000   \n",
       "50%                    0.000000               0.000000   \n",
       "75%                    0.000000               0.000000   \n",
       "max                    1.000000               1.000000   \n",
       "\n",
       "       native-country_ Taiwan  native-country_ Thailand  \\\n",
       "count            30162.000000              30162.000000   \n",
       "mean                 0.001392                  0.000564   \n",
       "std                  0.037291                  0.023734   \n",
       "min                  0.000000                  0.000000   \n",
       "25%                  0.000000                  0.000000   \n",
       "50%                  0.000000                  0.000000   \n",
       "75%                  0.000000                  0.000000   \n",
       "max                  1.000000                  1.000000   \n",
       "\n",
       "       native-country_ Trinadad&Tobago  native-country_ United-States  \\\n",
       "count                     30162.000000                   30162.000000   \n",
       "mean                          0.000597                       0.911876   \n",
       "std                           0.024422                       0.283480   \n",
       "min                           0.000000                       0.000000   \n",
       "25%                           0.000000                       1.000000   \n",
       "50%                           0.000000                       1.000000   \n",
       "75%                           0.000000                       1.000000   \n",
       "max                           1.000000                       1.000000   \n",
       "\n",
       "       native-country_ Vietnam  native-country_ Yugoslavia  \n",
       "count             30162.000000                30162.000000  \n",
       "mean                  0.002122                    0.000530  \n",
       "std                   0.046016                    0.023026  \n",
       "min                   0.000000                    0.000000  \n",
       "25%                   0.000000                    0.000000  \n",
       "50%                   0.000000                    0.000000  \n",
       "75%                   0.000000                    0.000000  \n",
       "max                   1.000000                    1.000000  \n",
       "\n",
       "[8 rows x 102 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## summary statistics for your training and test datasets \n",
    "x_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    30162.000000\n",
       "mean         0.248922\n",
       "std          0.432396\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max          1.000000\n",
       "Name: income, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>workclass_ Private</th>\n",
       "      <th>workclass_ Self-emp-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_ Portugal</th>\n",
       "      <th>native-country_ Puerto-Rico</th>\n",
       "      <th>native-country_ Scotland</th>\n",
       "      <th>native-country_ South</th>\n",
       "      <th>native-country_ Taiwan</th>\n",
       "      <th>native-country_ Thailand</th>\n",
       "      <th>native-country_ Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_ United-States</th>\n",
       "      <th>native-country_ Vietnam</th>\n",
       "      <th>native-country_ Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15060.000000</td>\n",
       "      <td>1.506000e+04</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.768327</td>\n",
       "      <td>1.896164e+05</td>\n",
       "      <td>10.112749</td>\n",
       "      <td>1120.301594</td>\n",
       "      <td>89.041899</td>\n",
       "      <td>40.951594</td>\n",
       "      <td>0.030744</td>\n",
       "      <td>0.068592</td>\n",
       "      <td>0.731806</td>\n",
       "      <td>0.037981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>0.004382</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.915538</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.000465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.380676</td>\n",
       "      <td>1.056150e+05</td>\n",
       "      <td>2.558727</td>\n",
       "      <td>7703.181842</td>\n",
       "      <td>406.283245</td>\n",
       "      <td>12.062831</td>\n",
       "      <td>0.172628</td>\n",
       "      <td>0.252768</td>\n",
       "      <td>0.443034</td>\n",
       "      <td>0.191158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043080</td>\n",
       "      <td>0.066057</td>\n",
       "      <td>0.024440</td>\n",
       "      <td>0.044589</td>\n",
       "      <td>0.029369</td>\n",
       "      <td>0.028218</td>\n",
       "      <td>0.023043</td>\n",
       "      <td>0.278089</td>\n",
       "      <td>0.035498</td>\n",
       "      <td>0.021555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.349200e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.166550e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.779550e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.385888e+05</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.490400e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>3770.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "count  15060.000000  1.506000e+04   15060.000000  15060.000000  15060.000000   \n",
       "mean      38.768327  1.896164e+05      10.112749   1120.301594     89.041899   \n",
       "std       13.380676  1.056150e+05       2.558727   7703.181842    406.283245   \n",
       "min       17.000000  1.349200e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.166550e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.779550e+05      10.000000      0.000000      0.000000   \n",
       "75%       48.000000  2.385888e+05      13.000000      0.000000      0.000000   \n",
       "max       90.000000  1.490400e+06      16.000000  99999.000000   3770.000000   \n",
       "\n",
       "       hours-per-week  workclass_ Federal-gov  workclass_ Local-gov  \\\n",
       "count    15060.000000            15060.000000          15060.000000   \n",
       "mean        40.951594                0.030744              0.068592   \n",
       "std         12.062831                0.172628              0.252768   \n",
       "min          1.000000                0.000000              0.000000   \n",
       "25%         40.000000                0.000000              0.000000   \n",
       "50%         40.000000                0.000000              0.000000   \n",
       "75%         45.000000                0.000000              0.000000   \n",
       "max         99.000000                1.000000              1.000000   \n",
       "\n",
       "       workclass_ Private  workclass_ Self-emp-inc  ...  \\\n",
       "count        15060.000000             15060.000000  ...   \n",
       "mean             0.731806                 0.037981  ...   \n",
       "std              0.443034                 0.191158  ...   \n",
       "min              0.000000                 0.000000  ...   \n",
       "25%              0.000000                 0.000000  ...   \n",
       "50%              1.000000                 0.000000  ...   \n",
       "75%              1.000000                 0.000000  ...   \n",
       "max              1.000000                 1.000000  ...   \n",
       "\n",
       "       native-country_ Portugal  native-country_ Puerto-Rico  \\\n",
       "count              15060.000000                 15060.000000   \n",
       "mean                   0.001859                     0.004382   \n",
       "std                    0.043080                     0.066057   \n",
       "min                    0.000000                     0.000000   \n",
       "25%                    0.000000                     0.000000   \n",
       "50%                    0.000000                     0.000000   \n",
       "75%                    0.000000                     0.000000   \n",
       "max                    1.000000                     1.000000   \n",
       "\n",
       "       native-country_ Scotland  native-country_ South  \\\n",
       "count              15060.000000           15060.000000   \n",
       "mean                   0.000598               0.001992   \n",
       "std                    0.024440               0.044589   \n",
       "min                    0.000000               0.000000   \n",
       "25%                    0.000000               0.000000   \n",
       "50%                    0.000000               0.000000   \n",
       "75%                    0.000000               0.000000   \n",
       "max                    1.000000               1.000000   \n",
       "\n",
       "       native-country_ Taiwan  native-country_ Thailand  \\\n",
       "count            15060.000000              15060.000000   \n",
       "mean                 0.000863                  0.000797   \n",
       "std                  0.029369                  0.028218   \n",
       "min                  0.000000                  0.000000   \n",
       "25%                  0.000000                  0.000000   \n",
       "50%                  0.000000                  0.000000   \n",
       "75%                  0.000000                  0.000000   \n",
       "max                  1.000000                  1.000000   \n",
       "\n",
       "       native-country_ Trinadad&Tobago  native-country_ United-States  \\\n",
       "count                     15060.000000                   15060.000000   \n",
       "mean                          0.000531                       0.915538   \n",
       "std                           0.023043                       0.278089   \n",
       "min                           0.000000                       0.000000   \n",
       "25%                           0.000000                       1.000000   \n",
       "50%                           0.000000                       1.000000   \n",
       "75%                           0.000000                       1.000000   \n",
       "max                           1.000000                       1.000000   \n",
       "\n",
       "       native-country_ Vietnam  native-country_ Yugoslavia  \n",
       "count             15060.000000                15060.000000  \n",
       "mean                  0.001262                    0.000465  \n",
       "std                   0.035498                    0.021555  \n",
       "min                   0.000000                    0.000000  \n",
       "25%                   0.000000                    0.000000  \n",
       "50%                   0.000000                    0.000000  \n",
       "75%                   0.000000                    0.000000  \n",
       "max                   1.000000                    1.000000  \n",
       "\n",
       "[8 rows x 102 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    15060.000000\n",
       "mean         0.245684\n",
       "std          0.430506\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max          1.000000\n",
       "Name: income, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eZvPsvq_6dQW"
   },
   "outputs": [],
   "source": [
    "x_train=np.array(x_train)\n",
    "y_train=np.array(y_train)\n",
    "x_test=np.array(x_test)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZZuAiUTw7lpF"
   },
   "source": [
    "## Q1.2 & Q1.3\n",
    "#### Derive the gradient and hessian matrix for the new E(w).\n",
    "#### Create your mylogistic_l2 class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1lSLNE9v6m4p"
   },
   "outputs": [],
   "source": [
    "# sample use:\n",
    "# logic1 = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "# logic1.fit(X_train, Y_train)\n",
    "# ypred = logic1.predict(X_test)\n",
    "\n",
    "\n",
    "class mylogistic_l2:\n",
    "    def __init__(self, reg_vec, max_iter, tol, add_intercept):\n",
    "        self.reg_vec = reg_vec\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.add_intercept = add_intercept\n",
    "\n",
    "    \n",
    "    def fit(self,X_train,Y_train):\n",
    "        if self.add_intercept == True:\n",
    "            X_train = np.concatenate((np.ones((X_train.shape[0],1)),X_train), axis = 1)\n",
    "        self.w = np.dot(np.dot(np.linalg.inv(np.dot(X_train.T,X_train)+np.identity(X_train.shape[1])*self.reg_vec.mean()),X_train.T),Y_train)\n",
    "        error = [0]\n",
    "        \n",
    "        for i in range(1,self.max_iter):\n",
    "            z = np.dot(X_train, np.transpose(self.w))\n",
    "            \n",
    "            ## Q1.2 \n",
    "            #### Derive the gradient and hessian matrix for the new E(w).\n",
    "            ### y: predicted value after sigmoid function\n",
    "            y = 1 / (1.0 + np.exp(-z))\n",
    "           \n",
    "            reg_term=(1/2)*np.dot(np.dot(self.w.T,np.diag(self.reg_vec.ravel())),self.w)\n",
    "            \n",
    "            cross_entropy = (-1 * (np.dot(np.squeeze(Y_train), np.log(y)) + np.dot((1 - np.squeeze(Y_train)), np.log(1 - y)))+reg_term)/X_train.shape[0]\n",
    "            error.append(cross_entropy)\n",
    "            \n",
    "            ### w_grad of the E(w)\n",
    "            w_grad = X_train.T.dot(y-Y_train)+self.reg_vec*self.w\n",
    "            \n",
    "            ### hession matrix for the E(w)\n",
    "            ds = y*(1-y)\n",
    "            D = np.diag(ds.ravel()) \n",
    "            H =  X_train.T.dot( D.dot(X_train) )+np.identity(self.reg_vec.shape[0])*self.reg_vec\n",
    "            #update w\n",
    "            self.w = self.w -np.linalg.inv(H).dot(w_grad)\n",
    "            \n",
    "            ### update rule:\n",
    "            if i > 1:\n",
    "                if error[i-1]-error[i]<self.tol:\n",
    "                    break\n",
    "                    \n",
    "    def predict(self,X_test):\n",
    "        if self.add_intercept == True:\n",
    "            X_test = np.concatenate((np.ones((X_test.shape[0],1)),X_test), axis = 1)\n",
    "        z = np.dot(X_test,self.w) \n",
    "        y = 1 / (1.0 + np.exp(-z))\n",
    "        y_ = np.where(y>= 0.5, 1, 0)\n",
    "        return y_, self.w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s8VOmETs7uaO"
   },
   "source": [
    "#### Case 1: \n",
    "lambda = 1 for all coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 48914,
     "status": "ok",
     "timestamp": 1587627355757,
     "user": {
      "displayName": "lalami",
      "photoUrl": "",
      "userId": "13790229632949164922"
     },
     "user_tz": -480
    },
    "id": "IhimyQkG6m93",
    "outputId": "bdcae605-521d-49b5-c1cf-479f03315646"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print the learned w \n",
      " [-3.33374540e+00  2.48591297e-02  7.26281835e-07  1.85806163e-01\n",
      "  3.16590245e-04  6.38679434e-04  2.90215841e-02  1.89694411e-01\n",
      " -4.97719501e-01 -3.10975202e-01 -1.29181491e-01 -7.94111556e-01\n",
      " -6.18745003e-01 -1.17270706e+00 -4.52249247e-01 -5.44907403e-01\n",
      " -3.82721832e-01 -9.99810289e-02 -2.62922225e-01 -6.29791388e-01\n",
      " -4.96565839e-01 -3.08326937e-01 -1.27584811e-01  1.28534378e-01\n",
      "  5.87953355e-01 -2.50481306e-01  2.99991415e-01 -1.37579993e+00\n",
      "  6.82097029e-01 -1.00989638e-01 -1.00975740e+00  1.19612258e+00\n",
      "  8.38966933e-01 -9.56673066e-01 -1.50523218e+00 -1.08232391e+00\n",
      " -8.14848363e-01 -8.78492150e-02 -2.46913576e-02  7.15174653e-01\n",
      " -1.06504054e+00 -7.73348089e-01 -3.53722827e-01 -9.03671285e-01\n",
      " -1.69395623e+00  4.29670534e-01  4.99488476e-01  2.05962313e-01\n",
      "  5.68478621e-01 -1.78947443e-01 -5.76254828e-01 -3.75781253e-01\n",
      " -1.12608337e+00 -1.50192087e+00 -5.01524915e-01  7.47819835e-01\n",
      " -1.02439618e+00 -2.92668732e-01 -6.35195701e-01 -8.96890177e-01\n",
      " -4.84594618e-01 -2.09367501e+00 -1.24007039e+00  9.03420736e-01\n",
      "  4.04668560e-01 -5.46920552e-01 -1.31374667e+00  4.27865170e-01\n",
      " -9.47705967e-01 -1.07395557e-01 -4.09492097e-01  3.77034140e-01\n",
      "  5.45751678e-01  5.23589384e-01 -6.70323916e-01 -1.09516216e-01\n",
      "  4.53277949e-02 -1.63971889e-01 -4.71983494e-02 -4.02281380e-03\n",
      " -3.44708811e-01  1.03362979e-01  4.50497096e-01  8.22875669e-01\n",
      "  9.41389495e-02  2.92357805e-01 -3.50891475e-01 -4.39859204e-01\n",
      " -4.07586321e-01 -6.90804284e-01 -4.47783816e-01  3.91129903e-01\n",
      "  8.03243762e-02  7.97357705e-02 -1.81402777e-01 -9.03628229e-02\n",
      " -9.81576059e-01 -7.79910247e-02 -3.31100773e-01 -1.88816101e-01\n",
      "  2.89337136e-01 -8.34197419e-01  5.39068128e-01]\n",
      "print test accuracy \n",
      " 0.8480743691899071\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(x_train.shape[1] + 1)\n",
    "logic1 = mylogistic_l2(max_iter = 100, add_intercept = True, reg_vec = a, tol = 1e-5)\n",
    "logic1.fit(x_train, y_train)\n",
    "ypred = logic1.predict(x_test)\n",
    "print(\"print the learned w\",\"\\n\",ypred[1])\n",
    "print(\"print test accuracy\",\"\\n\",(ypred[0] == y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r9gqqPW292cU"
   },
   "source": [
    "#### Case 2: \n",
    "lambda = 1 for all but the intercept, no regularization for incercept term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 42226,
     "status": "ok",
     "timestamp": 1587627463836,
     "user": {
      "displayName": "lalami",
      "photoUrl": "",
      "userId": "13790229632949164922"
     },
     "user_tz": -480
    },
    "id": "-zfPfvj66nDQ",
    "outputId": "35ad4f77-f365-4b2c-bc46-ffcbefb12ebe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print the learned w \n",
      " [-8.88722778e+00  2.54336822e-02  7.50706804e-07  2.95324923e-01\n",
      "  3.17024478e-04  6.39652126e-04  2.94914512e-02  7.05717318e-01\n",
      "  1.78026502e-02  2.09126595e-01  3.82731145e-01 -2.79821710e-01\n",
      " -1.04552949e-01 -9.31003049e-01  9.08118759e-02 -1.06210390e-01\n",
      " -5.68864876e-02  7.06129017e-01  5.36014978e-01  1.16361326e-01\n",
      "  1.37527872e-01 -4.01951495e-01 -1.13370201e-01 -7.43801938e-02\n",
      "  6.79669927e-02 -1.95742295e-02 -1.15929725e-02 -1.15969699e+00\n",
      "  2.67049827e-01  2.18010722e-02 -5.26538170e-01  1.61452756e+00\n",
      "  1.36750998e+00 -4.92456773e-01 -1.01532721e+00 -6.05766406e-01\n",
      " -3.41948994e-01  1.64109182e-01  2.28422252e-01  9.64856017e-01\n",
      " -8.17967488e-01 -5.20782272e-01 -9.91243553e-02 -6.49283758e-01\n",
      " -1.55300394e+00  6.78427763e-01  7.51030496e-01  4.55411798e-01\n",
      "  8.18714334e-01  7.31938650e-02 -4.21151177e-02  1.99456835e-01\n",
      " -5.83542676e-01 -9.36996676e-01  7.53014460e-02  1.28789619e+00\n",
      " -3.72048376e-01  3.94360616e-01  4.30693947e-02 -2.61235809e-01\n",
      "  1.95854174e-01 -4.27150728e-01  4.27150728e-01  1.00965472e+00\n",
      "  5.02337197e-01 -4.58396920e-01 -1.24053337e+00  5.27833699e-01\n",
      " -8.67620758e-01 -2.75702542e-02 -3.15345727e-01  4.72832596e-01\n",
      "  6.28755385e-01  6.23911101e-01 -5.88433187e-01 -2.96923356e-02\n",
      "  1.24844059e-01 -1.43574429e-01  2.48070503e-02  6.14826821e-02\n",
      " -2.48769642e-01  1.94794455e-01  5.25952046e-01  9.31972681e-01\n",
      "  1.87606692e-01  3.79606530e-01 -2.87259337e-01 -3.10421302e-01\n",
      " -3.32413818e-01 -6.50777756e-01 -3.81261235e-01  4.89030076e-01\n",
      "  1.76281854e-01  1.74545517e-01 -7.36414561e-02 -3.10934765e-02\n",
      " -8.98503738e-01  6.72286166e-03 -2.72168680e-01 -1.23870297e-01\n",
      "  3.96789072e-01 -7.54273374e-01  6.10526925e-01]\n",
      "print test accuracy \n",
      " 0.847808764940239\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(x_train.shape[1] + 1)\n",
    "a[0] = 0  #set the weight of intercept to 0\n",
    "logic1 = mylogistic_l2(max_iter = 100,add_intercept = True,reg_vec = a,tol=1e-5)\n",
    "logic1.fit(x_train, y_train)\n",
    "ypred = logic1.predict(x_test)\n",
    "print(\"print the learned w\",\"\\n\",ypred[1])\n",
    "print(\"print test accuracy\",\"\\n\",(ypred[0] == y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G2ESlwKK-xdy"
   },
   "source": [
    "#### Case 3: \n",
    "lambda = 1 for numerical-valued features, lambda = 0.5 for binary-valued features, no regularization for incercept term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1136,
     "status": "ok",
     "timestamp": 1587627651099,
     "user": {
      "displayName": "lalami",
      "photoUrl": "",
      "userId": "13790229632949164922"
     },
     "user_tz": -480
    },
    "id": "mEkRIT23rY5b",
    "outputId": "3c759d61-599d-4163-dd2d-da5e7032ecd6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 1, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, ..., 1, 0, 0],\n",
       "       [0, 0, 1, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dummy variable start from six\n",
    "x_train[:,6:]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 45794,
     "status": "ok",
     "timestamp": 1587627711649,
     "user": {
      "displayName": "lalami",
      "photoUrl": "",
      "userId": "13790229632949164922"
     },
     "user_tz": -480
    },
    "id": "TKn8UpN8-6Mm",
    "outputId": "3e3f6a46-b62b-4d75-fa50-fc58cf81d08f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print the learned w \n",
      " [-9.31135249e+00  2.54757380e-02  7.51944447e-07  3.19092334e-01\n",
      "  3.17319918e-04  6.40115467e-04  2.95136416e-02  7.66990129e-01\n",
      "  7.62915572e-02  2.68338062e-01  4.43127805e-01 -2.20821183e-01\n",
      " -4.63421363e-02 -1.28758423e+00  2.18992444e-01 -2.26135094e-03\n",
      "  2.18816221e-02  9.74981515e-01  7.54034090e-01  2.92224599e-01\n",
      "  2.93070047e-01 -4.19612047e-01 -1.04346432e-01 -1.12963353e-01\n",
      " -3.78241652e-02  3.76517948e-02 -7.30515953e-02 -2.08394381e+00\n",
      "  1.86338326e-01  5.48283203e-02 -5.72016479e-01  1.82571076e+00\n",
      "  1.39641686e+00 -5.47067030e-01 -1.05936555e+00 -6.55642109e-01\n",
      " -3.88036449e-01  2.36234568e-01  3.00253587e-01  1.03825742e+00\n",
      " -7.52670195e-01 -4.53424296e-01 -2.69070976e-02 -5.82347486e-01\n",
      " -2.00233663e+00  7.51037287e-01  8.27361959e-01  5.28329988e-01\n",
      "  8.95058089e-01  1.45241736e-01 -8.34438876e-02  2.32698984e-01\n",
      " -5.92702310e-01 -9.22764380e-01  1.11240494e-01  1.25497110e+00\n",
      " -3.83664223e-01  4.13058389e-01  4.13741722e-02 -2.63868110e-01\n",
      "  1.93099772e-01 -4.29102280e-01  4.29102280e-01  1.18913504e+00\n",
      "  5.50823621e-01 -4.76703416e-01 -1.45906507e+00  5.82266388e-01\n",
      " -1.06198169e+00 -9.41595511e-03 -3.18451269e-01  5.24213619e-01\n",
      "  7.29262486e-01  6.74417704e-01 -6.38234075e-01 -9.70370974e-03\n",
      "  1.74243036e-01 -2.36216830e-01  3.80747425e-02  1.00364860e-01\n",
      " -2.47188656e-01  2.38206872e-01  6.41987645e-01  1.00609325e+00\n",
      "  2.33159600e-01  4.22777999e-01 -3.53092034e-01 -2.90744304e-01\n",
      " -3.80715988e-01 -9.62423309e-01 -4.49691900e-01  5.13214010e-01\n",
      "  2.19833007e-01  2.27002306e-01 -5.01168975e-02 -1.79083299e-02\n",
      " -9.59642325e-01  1.67396852e-02 -3.27258263e-01 -1.39435434e-01\n",
      "  4.28358927e-01 -8.46070010e-01  7.51083104e-01]\n",
      "print test accuracy \n",
      " 0.847675962815405\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(x_train.shape[1] + 1)\n",
    "a[0] = 0 #set the weight of intercept to 0\n",
    "a[6:] = 0.5\n",
    "logic1 = mylogistic_l2(max_iter =100,add_intercept=True,reg_vec =a,tol=1e-5)\n",
    "logic1.fit(x_train, y_train)\n",
    "ypred = logic1.predict(x_test)\n",
    "print(\"print the learned w\",\"\\n\",ypred[1])\n",
    "print(\"print test accuracy\",\"\\n\",(ypred[0] == y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6rDjgHhQ-_G3"
   },
   "source": [
    "# Q1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2lCu05IB_eup"
   },
   "source": [
    "conduct grid search with the constraint that a1=a2 . Record the best value a∗1 and a∗2 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J7fw9SBi_Ns3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27146, 102)\n",
      "(27146,)\n",
      "(3016, 102)\n",
      "(3016,)\n"
     ]
    }
   ],
   "source": [
    "# Further split the training data into subtraining (90%) and tuning (10%) \n",
    "# to search for the best hyperparameters. \n",
    "\n",
    "all = len(x_train)\n",
    "valid = int(math.floor(all * 0.1)) # Round down\n",
    "\n",
    "X_valid = x_train[0:valid]\n",
    "Y_valid = y_train[0:valid]\n",
    "X_train = x_train[valid:]\n",
    "Y_train = y_train[valid:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(Y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0vfj7f3yrae3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.000e-02 1.112e+01 2.223e+01 3.334e+01 4.445e+01 5.556e+01 6.667e+01\n",
      " 7.778e+01 8.889e+01 1.000e+02]\n"
     ]
    }
   ],
   "source": [
    "# Step 1:\n",
    "# choose a set of grids among a reasonable range.\n",
    "# evenly dispersed points (start, stop, num)\n",
    "find = np.linspace(0.01,100, num=10) \n",
    "print(find)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S3WtHPVl_VNE"
   },
   "outputs": [],
   "source": [
    "# Step 2:\n",
    "# Conduct grid search with the constraint that  a1=a2\n",
    "# Record the best value  a∗1  and  a∗2 .\n",
    "a = np.ones(x_train.shape[1] + 1)\n",
    "a[0] = 0 #set the weight of intercept to 0\n",
    "collect = []\n",
    "for i in range(len(find)):\n",
    "    a = np.ones(x_train.shape[1] + 1)\n",
    "    a[0] = 0  \n",
    "    a[1:]= find[i]\n",
    "    logic1 = mylogistic_l2(max_iter =100,add_intercept=True,reg_vec =a,tol=1e-5)\n",
    "    logic1.fit(X_train, Y_train)\n",
    "    ypred = logic1.predict(X_valid)\n",
    "    ans = (ypred[0]==Y_valid).sum()\n",
    "    collect.append(ans/len(Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1166,
     "status": "ok",
     "timestamp": 1587628156056,
     "user": {
      "displayName": "lalami",
      "photoUrl": "",
      "userId": "13790229632949164922"
     },
     "user_tz": -480
    },
    "id": "jYCZ3bGh_W3m",
    "outputId": "f2012290-68a4-4890-84e7-07a24d6f5ccb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = np.argmax(collect)\n",
    "minnumber = find[ans]\n",
    "# when a1=a2, the best regularization coefficients\n",
    "# the best value  of a∗1 and a∗2\n",
    "minnumber "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9x5QejDc_qQ3"
   },
   "outputs": [],
   "source": [
    "# Step 3:\n",
    "# Fix a1=a∗1 , and search a2 for the best value\n",
    "# call the result the new a∗2 .\n",
    "a = np.ones(x_train.shape[1] + 1)\n",
    "a[0] = 0 \n",
    "collect = []\n",
    "for i in range(len(find)):\n",
    "    a = np.ones(x_train.shape[1] + 1)\n",
    "    a[0] = 0  \n",
    "    a[:6] = 0.01 ##Fix a1=a∗1 \n",
    "    a[6:] = find[i]\n",
    "    logic1 = mylogistic_l2(max_iter =100,add_intercept=True,reg_vec =a,tol=1e-5)\n",
    "    logic1.fit(X_train, Y_train)\n",
    "    ypred = logic1.predict(X_valid)\n",
    "    ans=(ypred[0]==Y_valid).sum()\n",
    "    collect.append(ans/len(Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1170,
     "status": "ok",
     "timestamp": 1587629166889,
     "user": {
      "displayName": "lalami",
      "photoUrl": "",
      "userId": "13790229632949164922"
     },
     "user_tz": -480
    },
    "id": "nHhTReI1_tZq",
    "outputId": "0cb0f496-c8db-44c0-9cc8-02a8333731cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans=np.argmax(collect)\n",
    "minnumber=find[ans]\n",
    "# when a1=a*1, the best a2\n",
    "minnumber  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nI87A2f9_xmj"
   },
   "outputs": [],
   "source": [
    "# Step 4:\n",
    "# Fix a2 = a∗2 , and search a1 for the best value.v\n",
    "a = np.ones(x_train.shape[1] + 1)\n",
    "a[0] = 0 \n",
    "collect = []\n",
    "for i in range(len(find)):\n",
    "    a = np.ones(x_train.shape[1] + 1)\n",
    "    a[0] = 0  \n",
    "    a[6:] = 0.01 ##Fix a2=a∗2\n",
    "    a[:6] = find[i]\n",
    "    logic1 = mylogistic_l2(max_iter =100,add_intercept=True,reg_vec =a,tol=1e-5)\n",
    "    logic1.fit(X_train, Y_train)\n",
    "    ypred = logic1.predict(X_valid)\n",
    "    ans=(ypred[0]==Y_valid).sum()\n",
    "    collect.append(ans/len(Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FlmUVseX_zdw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = np.argmax(collect)\n",
    "minnumber = find[ans]\n",
    "# when a2=a*2, the best a1\n",
    "minnumber  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5:\n",
    "# Report the selected a1 and a2 \n",
    "# the best choice is ： a1=a∗1 and a2=a∗2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 41991,
     "status": "ok",
     "timestamp": 1587628151990,
     "user": {
      "displayName": "lalami",
      "photoUrl": "",
      "userId": "13790229632949164922"
     },
     "user_tz": -480
    },
    "id": "iwxhojzA_73-",
    "outputId": "c7af3479-d014-4291-f6a0-84db536005f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.847808764940239\n"
     ]
    }
   ],
   "source": [
    "# Step 6:\n",
    "# Train a model using the selected hyper-parameters\n",
    "# and report the test accuracy.\n",
    "a[0] = 0  \n",
    "a[1:] = 0.01\n",
    "logic1 = mylogistic_l2(max_iter =100,add_intercept=True,reg_vec =a,tol=1e-5)\n",
    "logic1.fit(x_train,y_train)\n",
    "ypred = logic1.predict(x_test)\n",
    "\n",
    "# print test accuracy\n",
    "acc = (ypred[0]==y_test).sum()/len(y_test)\n",
    "print(\"test accuracy\",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kYsFOLSW_DqI"
   },
   "source": [
    "# Q1.5\n",
    "\n",
    "Use sklearn.linear_model.LogisticRegression to train and test the model (including hyper-parameter tuning). Compare the estimated parameters and test accuracy with those from your own models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kBc6AM8yrhyK"
   },
   "outputs": [],
   "source": [
    "# with sklearn.linear_model.LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "r=[]                    \n",
    "for alpha in find:\n",
    "    clf = LogisticRegression(penalty=\"l2\",C=alpha).fit(X_train, Y_train)\n",
    "    ypred=clf.predict(X_valid)\n",
    "    acc=(ypred==Y_valid).sum()/len(Y_valid)\n",
    "    r.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YeIk7Zv4EwcZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.argmax(r)\n",
    "ans = find[a]\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cayz97qzE_ES"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy of sklearn model 0.7944887118193891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\lalami\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(penalty=\"l2\",C=0.01).fit(x_train, y_train)\n",
    "ypred = clf.predict(x_test)\n",
    "acc = (ypred==y_test).sum()/len(ypred)\n",
    "\n",
    "# Compare the test accuracy \n",
    "print(\"test accuracy of sklearn model\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5SvBhVlqFBAc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy of my model 0.847808764940239\n"
     ]
    }
   ],
   "source": [
    "#with my own model\n",
    "a=np.ones(x_train.shape[1] + 1)\n",
    "a[0]=0  \n",
    "a[1:]=0.01\n",
    "logic1 = mylogistic_l2(max_iter =100,add_intercept=True,reg_vec =a,tol=1e-5)\n",
    "logic1.fit(x_train,y_train)\n",
    "ypred = logic1.predict(x_test)\n",
    "acc=(ypred[0]==y_test).sum()/len(y_test)\n",
    "print(\"test accuracy of my model\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k1lFQ7CbFCzY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the estimated parameters of sklearn model\n",
      "[[ 2.94298860e-03 -3.95344524e-06 -3.13044246e-03  3.22502109e-04\n",
      "   8.46122953e-04 -1.74357732e-02  6.81470567e-04  2.10670636e-04\n",
      "  -9.13631093e-03  1.63903756e-03 -1.43066354e-04 -1.29033740e-04\n",
      "  -2.82392735e-05 -1.09207798e-03 -1.61307198e-03 -5.07654306e-04\n",
      "  -1.94554250e-04 -3.92017121e-04 -7.67528493e-04 -6.13915782e-04\n",
      "  -1.47414353e-04 -1.88633982e-04  4.29883752e-03  1.04929331e-03\n",
      "  -7.12470553e-03  2.69767891e-03 -7.97277404e-05  1.27687044e-03\n",
      "  -3.50685021e-03 -4.85491377e-03  3.40058531e-05  1.60791403e-02\n",
      "  -4.64807146e-04 -1.54294366e-02 -1.23600447e-03 -1.03345570e-03\n",
      "  -3.58066005e-03 -1.25493415e-03  4.94104717e-03 -1.11393802e-03\n",
      "  -1.88296406e-03 -1.85296922e-03 -5.10039763e-03 -2.53043438e-04\n",
      "   3.79493564e-03  3.06933691e-04 -3.93874062e-04  1.74928484e-04\n",
      "  -6.81568990e-04  1.44363598e-02 -9.18322629e-03 -1.36955170e-03\n",
      "  -8.18620036e-03 -4.44481910e-03  1.84196613e-03 -4.15476227e-04\n",
      "  -1.36577238e-04 -2.34474634e-03 -2.82686361e-04 -3.72598537e-03\n",
      "  -1.12624360e-02  4.35696447e-03  1.11400267e-05  3.11662604e-05\n",
      "   2.80702015e-06 -7.93266070e-05  3.62428416e-05 -1.03844319e-04\n",
      "  -2.32301879e-05 -1.09963914e-04  3.89823545e-05  3.86403170e-05\n",
      "   5.71054468e-05 -2.02350493e-05 -7.74874387e-05 -4.13498604e-05\n",
      "  -1.24125831e-05  1.32008334e-05 -6.53843978e-06  5.71025043e-05\n",
      "   2.94680853e-05 -1.46871548e-05  4.41072411e-05 -6.50761957e-05\n",
      "   3.97945721e-05 -1.32656612e-05 -6.12919202e-04 -3.62771196e-05\n",
      "  -2.20534403e-05 -2.99274655e-05  3.51072502e-05 -2.55645501e-05\n",
      "  -3.80900196e-05 -1.12005899e-04 -4.14816843e-06 -4.99946230e-05\n",
      "   5.22421360e-05 -5.40874011e-06 -2.09253467e-05 -5.77232079e-03\n",
      "  -1.07163630e-04  1.71639614e-05]]\n",
      "[-0.00690608]\n"
     ]
    }
   ],
   "source": [
    "# Compare the estimated parameters\n",
    "print(\"the estimated parameters of sklearn model\")\n",
    "print(clf.coef_)\n",
    "print(clf.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RkeLXM5HFFMx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the estimated parameters of my model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.14761639e+01,  2.55402069e-02,  7.54179075e-07,  3.99000844e-01,\n",
       "        3.18079304e-04,  6.40833979e-04,  2.95698399e-02,  1.18875412e+00,\n",
       "        4.92451904e-01,  6.84930795e-01,  8.61390951e-01,  1.95387325e-01,\n",
       "        3.70139269e-01, -3.79305437e+00,  6.42711568e-01,  3.40923489e-01,\n",
       "        2.87599360e-01,  1.80393087e+00,  1.45363314e+00,  8.78329015e-01,\n",
       "        8.06064563e-01, -4.81427165e-01, -8.29135223e-02, -2.51104361e-01,\n",
       "       -4.13705383e-01,  2.19646908e-01, -2.90687139e-01, -4.96327039e+00,\n",
       "       -1.06146525e-01,  1.56415569e-01, -6.32068788e-01,  2.09585250e+00,\n",
       "        1.43979783e+00, -6.18496764e-01, -1.11726140e+00, -7.20624634e-01,\n",
       "       -4.47198738e-01,  9.58865053e-01,  1.02259679e+00,  1.76270281e+00,\n",
       "       -3.59538839e-02,  2.65170841e-01,  6.99095129e-01,  1.35348361e-01,\n",
       "       -3.04316652e+00,  1.47439297e+00,  1.55517451e+00,  1.25201407e+00,\n",
       "        1.62275162e+00,  8.68137958e-01, -1.42337820e-01,  2.77065751e-01,\n",
       "       -6.00456094e-01, -9.01122866e-01,  1.59280654e-01,  1.20757038e+00,\n",
       "       -3.95401661e-01,  4.31376543e-01,  3.79491340e-02, -2.63227496e-01,\n",
       "        1.89303480e-01, -4.30803553e-01,  4.30803553e-01,  1.68638160e+00,\n",
       "        7.05278173e-01, -3.90333501e-01, -1.74332147e+00,  7.42926686e-01,\n",
       "       -1.37449425e+00,  1.17977183e-01, -2.09897572e-01,  6.83083694e-01,\n",
       "        9.57663681e-01,  8.30967235e-01, -6.01034658e-01,  1.21488066e-01,\n",
       "        3.46889971e-01, -7.43147201e-01,  1.59497124e-01,  2.63598839e-01,\n",
       "       -1.39428131e-01,  3.92553770e-01,  9.01130513e-01,  1.18509717e+00,\n",
       "        3.90800047e-01,  5.74240585e-01, -3.65638884e-01, -1.66850215e-01,\n",
       "       -3.42972337e-01, -3.54521209e+00, -4.65119580e-01,  6.40919506e-01,\n",
       "        3.72154427e-01,  3.95086178e-01,  7.71642842e-02,  1.07463736e-01,\n",
       "       -9.29193684e-01,  1.31997436e-01, -3.16065521e-01, -6.51226732e-02,\n",
       "        5.63216780e-01, -8.71078185e-01,  1.05202109e+00])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"the estimated parameters of my model\")\n",
    "ypred[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zooi3SkyFIeJ"
   },
   "source": [
    "### Compared two model\n",
    "the estimated parameters of my own model is bigger but test accuracy is higher than sklearn.linear_model.LogisticRegression\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMNr7vER8xMfOf1gzxeSFGY",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "b06705048_hw3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
